{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lib imports and Authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
    "from azure.cognitiveservices.vision.computervision.models import OperationStatusCodes\n",
    "from azure.cognitiveservices.vision.computervision.models import VisualFeatureTypes\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "\n",
    "from array import array\n",
    "import os\n",
    "from PIL import Image\n",
    "import sys\n",
    "import time\n",
    "\n",
    "'''\n",
    "Authenticates your credentials and creates a client.\n",
    "'''\n",
    "subscription_key = \"f787a15468354d3cb3d6b0989bda9b29\"\n",
    "endpoint = \"https://ocr-prototype.cognitiveservices.azure.com/\"\n",
    "\n",
    "computervision_client = ComputerVisionClient(endpoint, CognitiveServicesCredentials(subscription_key))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OCR read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Read File - remote =====\n",
      "The quick brown fox jumps\n",
      "[87.0, 653.0, 2574.0, 712.0, 2571.0, 865.0, 83.0, 820.0]\n",
      "over the lazy dog!\n",
      "[177.0, 1008.0, 1988.0, 1010.0, 1987.0, 1159.0, 177.0, 1150.0]\n",
      "\n",
      "End of Read File\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "OCR: Read File using the Read API, extract text - remote\n",
    "This example will extract text in an image, then print results, line by line.\n",
    "This API call can also extract handwriting style text (not shown).\n",
    "'''\n",
    "print(\"===== Read File - remote =====\")\n",
    "# Get an image with text\n",
    "read_image_url = \"https://raw.githubusercontent.com/MicrosoftDocs/azure-docs/master/articles/cognitive-services/Computer-vision/Images/readsample.jpg\"\n",
    "\n",
    "# Call API with URL and raw response (allows you to get the operation location)\n",
    "read_response = computervision_client.read(read_image_url,  raw=True)\n",
    "\n",
    "# Get the operation location (URL with an ID at the end) from the response\n",
    "read_operation_location = read_response.headers[\"Operation-Location\"]\n",
    "# Grab the ID from the URL\n",
    "operation_id = read_operation_location.split(\"/\")[-1]\n",
    "\n",
    "# Call the \"GET\" API and wait for it to retrieve the results \n",
    "while True:\n",
    "    read_result = computervision_client.get_read_result(operation_id)\n",
    "    if read_result.status not in ['notStarted', 'running']:\n",
    "        break\n",
    "    time.sleep(1)\n",
    "\n",
    "# Print the detected text, line by line\n",
    "if read_result.status == OperationStatusCodes.succeeded:\n",
    "    for text_result in read_result.analyze_result.read_results:\n",
    "        for line in text_result.lines:\n",
    "            print(line.text)\n",
    "            print(line.bounding_box)\n",
    "print()\n",
    "print(\"End of Read File\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Tag an image - remote =====\n",
      "Tags in the remote image: \n",
      "'outdoor' with confidence 99.00%\n",
      "'building' with confidence 98.81%\n",
      "'sky' with confidence 98.21%\n",
      "'stadium' with confidence 98.17%\n",
      "'ancient rome' with confidence 96.16%\n",
      "'ruins' with confidence 95.04%\n",
      "'amphitheatre' with confidence 93.99%\n",
      "'ancient roman architecture' with confidence 92.65%\n",
      "'historic site' with confidence 89.55%\n",
      "'ancient history' with confidence 89.54%\n",
      "'history' with confidence 86.72%\n",
      "'archaeological site' with confidence 84.41%\n",
      "'travel' with confidence 65.85%\n",
      "'large' with confidence 61.02%\n",
      "'city' with confidence 56.57%\n",
      "\n",
      "End of Tag an image\n"
     ]
    }
   ],
   "source": [
    "# Images used for the examples: Describe an image, Categorize an image, Tag an image, \n",
    "# Detect faces, Detect adult or racy content, Detect the color scheme, \n",
    "# Detect domain-specific content, Detect image types, Detect objects\n",
    "\n",
    "# images_folder = os.path.join (os.path.dirname(os.path.abspath(__file__)), \"images\")\n",
    "# remote_image_url = \"https://raw.githubusercontent.com/Azure-Samples/cognitive-services-sample-data-files/master/ComputerVision/Images/landmark.jpg\"\n",
    "remote_image_url = \"https://raw.githubusercontent.com/bxing2000/Data-Science/main/cognitive-services/images/landmark.jpg\"\n",
    "\n",
    "'''\n",
    "Tag an Image - remote\n",
    "This example returns a tag (key word) for each thing in the image.\n",
    "'''\n",
    "print(\"===== Tag an image - remote =====\")\n",
    "# Call API with remote image\n",
    "tags_result_remote = computervision_client.tag_image(remote_image_url)\n",
    "\n",
    "# Print results with confidence score\n",
    "print(\"Tags in the remote image: \")\n",
    "if (len(tags_result_remote.tags) == 0):\n",
    "    print(\"No tags detected.\")\n",
    "else:\n",
    "    for tag in tags_result_remote.tags:\n",
    "        print(\"'{}' with confidence {:.2f}%\".format(tag.name, tag.confidence * 100))\n",
    "print()\n",
    "print(\"End of Tag an image\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 ('myenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "51aece475e882dbfaff838a8fad7259eb200c654596baedda4089f553a2485b0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
