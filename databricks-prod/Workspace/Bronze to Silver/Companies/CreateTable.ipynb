{"cells":[{"cell_type":"code","source":["\n%sql\n-- drop table if exists silver.Companies\n"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["# lakeName = 'developmentanalytics'\n\ncommand = \"\"\"create table if not exists silver.Companies (\n  CompanyId int,\n  InstanceId smallint,\n  InstanceName string,\n  AccountId int,\n  AccountName string,\n  TierId tinyint,\n  TierName string,\n  Status string,\n  IsDeleted boolean,\n  IsActive boolean,\n  BillingCreatedUtc timestamp,\n  IsPending boolean,\n  NonCab boolean,\n  VerticalId int,\n  VerticalName string,\n  OperationalCreatedUtc timestamp,\n  DataPurgeCompleted boolean,\n  CompanyName string,\n  ContactName string,\n  Phone string,\n  ContactEmail string,\n  AddressLine2 string,\n  AddressLine1 string,\n  City string,\n  RegionName string,\n  PostalCode string,\n  CountryCode string,\n  SubRegionName string,\n  RegionCode string,\n  SubRegionCode string,\n  UserIntegrationType int,\n  Market string,\n  EnableCustomerDW boolean,\n  SetupCompletionTime timestamp,\n  Modified timestamp,\n  SilverModifiedUtc timestamp\n)\nUSING DELTA\n--PARTITIONED BY (date)\nLOCATION 'wasbs://silver@\"\"\"+lakeName+\"\"\".blob.core.windows.net/cab/companies'\"\"\"\n\nspark.sql(command)"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["# df = spark.sql(\"select * from Companies limit 0\"); #read silver table structure, this needed just to read table structure.\n# print(df.columns)\n\n\n"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["%sql\n--alter table Companies add columns ( data3 string )\n"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["%sql\n--describe Companies "],"metadata":{},"outputs":[],"execution_count":5}],"metadata":{"name":"CreateTable","notebookId":2415651579339424},"nbformat":4,"nbformat_minor":0}