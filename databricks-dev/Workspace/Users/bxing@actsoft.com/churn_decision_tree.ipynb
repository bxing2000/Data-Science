{"cells":[{"cell_type":"markdown","source":["Churn prediction\n-------------------\nCompany churn occurs when companies cancel subscriptions or subscriptions expires without renewals.  \nThis file uses DecisionTree to predict Churn."],"metadata":{}},{"cell_type":"code","source":["%run /Common/config_sandbox"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["Companies = spark.read.format('delta').load(\"/mnt/sandboxes/SampleDataSets/All/Companies_All\")\nAccounts = spark.read.format('delta').load(\"/mnt/sandboxes/SampleDataSets/All/Accounts_All\")\nPaymentInfo = spark.read.format('delta').load(\"/mnt/sandboxes/SampleDataSets/All/PaymentInfo_All\")\nLicenses = spark.read.format('delta').load(\"/mnt/sandboxes/SampleDataSets/All/Licenses_All\")\nTrips = spark.read.format('delta').load(\"/mnt/sandboxes/SampleDataSets/ByCompany/Trips_SampledByCompany_All\")\nFormHeader6Month = spark.read.format('delta').load(\"/mnt/sandboxes/SampleDataSets/All/FormHeader6Month\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":3},{"cell_type":"markdown","source":["**Create the churn dataframe for modeling:**\n1. Find billable Companies.\n2. Aggregate Licenses to company level.\n3. Get the churn dataframe by joining billable companies with aggregated licenses.\n4. TODO: aggregate trips and form submissions to the churn dataframe."],"metadata":{}},{"cell_type":"code","source":["from pyspark.sql.functions import sum, min, max, col, current_date, udf\nfrom pyspark.sql.types import *\n\nBillableCompanies = Companies.join(Accounts, Companies.AccountId == Accounts.AccountId) \\\n                             .join(PaymentInfo, Companies.AccountId == PaymentInfo.AccountId) \\\n                             .filter(PaymentInfo.Billable == True) \\\n                             .filter(Accounts.IsTest == False)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":5},{"cell_type":"code","source":["from datetime import datetime\n\nLicensesByCompany = Licenses.groupBy('CompanyId').agg(sum('Count').alias('Licenses'), min('CreatedOn').alias('Activation'), max('ExpirationDate').alias('Expiration'), max('DeactDate').alias('Deactivation')) \\\n                    .filter('Activation is not null')\n\n# We need a date to determine a company churn or not.\n# In theory, it should be today, but sandbox data are too\n# old to have no-churn. So we define a pred_datetime from the past.\npred_datetime = datetime(2019, 1, 1)\n\n@udf(returnType=BooleanType())\ndef isChurned(colDeactivation):\n  if colDeactivation is not None and colDeactivation < pred_datetime:\n     return True\n  return False\n\n#isChurned_udf = udf(isChurned, BooleanType())\n\n@udf(returnType=IntegerType())\ndef licenseDuration(colActivation, colDeactivation):\n  if colActivation is not None and colActivation < pred_datetime:\n    if colDeactivation is not None and colDeactivation < pred_datetime:\n      delta = colDeactivation - colActivation\n      return delta.days\n    else:\n      delta = pred_datetime - colActivation\n      return delta.days \n  return -1\n\n#ChurnByCompany = LicensesByCompany.withColumn('Churn', col('Deactivation').isNotNull() & (col('Deactivation') < current_date()))\nChurnByCompany = LicensesByCompany.withColumn('Duration', licenseDuration(col('Activation'), col('Deactivation'))).withColumn('Churn', isChurned(col('Deactivation')))\nChurnByCompanyX = ChurnByCompany.filter(ChurnByCompany.Duration != -1)\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":6},{"cell_type":"code","source":["BillableCompaniesWithLicenses = BillableCompanies.select(col('CompanyId'), col('CompanyName'), col('Tier'), col('SetupCompletionTime').alias('IsSetupComplete'), \\\n                                                         col('UserIntegrationType'), col('City'), col('RegionName'), col('PostalCode'), col('CountryCode'), \\\n                                                         col('CreationDate'), col('ModificationDate'), col('CarrierId'), col('Culture'), col('DynamicsGuid')) \\\n                                                 .join(ChurnByCompanyX, ChurnByCompanyX.CompanyId == BillableCompanies.CompanyId).drop(ChurnByCompanyX.CompanyId)\n\nBillableCompaniesWithLicenses = BillableCompaniesWithLicenses.withColumn('IsSetupComplete', BillableCompaniesWithLicenses.IsSetupComplete.isNotNull())\n\n# redorder columns by moving Last column Churn to the first\n#originalColumns = list(BillableCompaniesWithLicenses.columns)\n#total = len(originalColumns)\n#newColumns = [originalColumns[total-1]] + originalColumns[:total-2]\n#BillableCompaniesWithLicenses = BillableCompaniesWithLicenses[newColumns]\n                                                 \n#display(BillableCompaniesWithLicenses.filter('Churn = false'))\ndisplay(BillableCompaniesWithLicenses)"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["# define features and target\ncategorical_features = [\"Tier\", \"IsSetupComplete\", \"UserIntegrationType\"]\nnumerical_features = [\"Licenses\", \"Duration\"]\ntarget=\"Churn\"\n\n#display(BillableCompaniesWithLicenses[numerical_features].describe())"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["import platform\nimport pandas as pd\nimport sklearn\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\n\n# save dataframe as csv\n#BillableCompaniesWithLicenses.write.format(\"csv\").save(\"/mnt/sandboxes/BillX/billable_companies_with_licenses.csv\")\n\n# get pandas dataframe\ndf = BillableCompaniesWithLicenses.toPandas()\nprint(df.shape)\nprint(list(df.columns))\n    "],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["df.describe(include='all')"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["fig, ax = plt.subplots(1, 3, figsize=(14, 4))\nfor i, categorical_feature in enumerate(categorical_features):\n  df[categorical_feature].value_counts().plot(kind='bar', ax=ax[i], rot=0).set_title(categorical_feature)\n\nfig.tight_layout(pad=3.0)"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["fig, ax = plt.subplots(2, 2, figsize=(14, 6))\n\ndf[df.Churn == False][\"Licenses\"].hist(bins=3, color=\"blue\", alpha=0.5, ax=ax[0, 0]).set_title(\"Licenses\")\ndf[df.Churn == True][\"Licenses\"].hist(bins=30, color=\"red\", alpha=0.5, ax=ax[0, 1]).set_title(\"Licenses\")\n\ndf[df.Churn == False][\"Duration\"].hist(bins=30, color=\"blue\", alpha=0.5, ax=ax[1, 0]).set_title(\"Duration(days)\")\ndf[df.Churn == True][\"Duration\"].hist(bins=30, color=\"red\", alpha=0.5, ax=ax[1, 1]).set_title(\"Duration(days)\")\n\nfig.tight_layout(pad=3.0)\n\n#display(fig)"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["feature = 'IsSetupComplete'\nfig, ax = plt.subplots(1, 2, figsize=(14, 4))\ndf[df.Churn == False][feature].value_counts().plot(kind='bar', ax=ax[0], rot=0).set_title('not churned')\ndf[df.Churn == True][feature].value_counts().plot(kind='bar', ax=ax[1], rot=0).set_title('churned')"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":["**LabelEncoder** for categorical features is used here only for EDA. Later on in pipleline, we will use **OneHot encoder.**    \n**LabelEncoder** uses simple numbers and could cause confusion for model (see [the article here](https://medium.com/@contactsunny/label-encoder-vs-one-hot-encoder-in-machine-learning-3fc273365621))."],"metadata":{}},{"cell_type":"code","source":["from sklearn.preprocessing import LabelEncoder\n\ncategorical_feature_names = []\nlabel_encoders = {}\nfor categorical in categorical_features + [target]:\n    label_encoders[categorical] = LabelEncoder()\n    df[categorical] = label_encoders[categorical].fit_transform(df[categorical])\n    names = label_encoders[categorical].classes_.tolist()\n    print('Label encoder %s - values: %s' % (categorical, names))\n    if categorical == target:\n        continue\n    categorical_feature_names.extend([categorical + '_' + str(name) for name in names])\n    "],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"code","source":["import seaborn as sb\n\n# non numerical columns are being igored by corr(). Use LabeEncoder to convert categorical features \n# to numerical in order for corr().\ndf_corr = df[categorical_features + [target] + numerical_features]\n\n# print corr matrix\ndf_corr.corr()\n"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"code","source":["# draw heatmap\nsb.heatmap(df_corr.corr(), square=True, cmap='RdYlGn')"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"code","source":["from sklearn.pipeline import FeatureUnion, Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn import tree\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import StandardScaler\n\n\nclass ItemSelector(BaseEstimator, TransformerMixin):\n    def __init__(self, key):\n        self.key = key\n\n    def fit(self, x, y=None):\n        return self\n\n    def transform(self, df):\n        return df[self.key]\n\npipeline = Pipeline(\n    [\n        (\n            \"union\",\n            FeatureUnion(\n                transformer_list=[\n                    (\n                        \"categorical_features\",\n                        Pipeline(\n                            [\n                                (\"selector\", ItemSelector(key=categorical_features)),\n                                (\"onehot\", OneHotEncoder()),\n                            ]\n                        ),\n                    )\n                ]\n                + [\n                    (\n                        \"numerical_features\",\n                        Pipeline(\n                            [\n                                (\"selector\", ItemSelector(key=numerical_features)),\n                                (\"scaler\", StandardScaler()),\n                            ]\n                        ),\n                    )\n                ]\n            ),\n        ),\n        (\"classifier\", tree.DecisionTreeClassifier(max_depth=5, random_state=42)),\n    ]\n)"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"code","source":["#BillableCompaniesWithLicenses_SampledDF = BillableCompaniesWithLicenses.sample(False, 0.1, 42)\ndf_sampled = df.sample(replace=False, frac=1, random_state=42)\n\ndf_sampled.shape\n#display(df_sampled)"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"code","source":["# training the model\nfrom sklearn.model_selection import train_test_split\n\ndf_train, df_test = train_test_split(df_sampled, test_size=0.25, random_state=42)\n\nclf = pipeline.fit(df_train, df_train[target])\npred = pipeline.predict(df_test)\n\nprint('Accuracy of logistic regression classifier on test set: {:.2f}'.format(pipeline.score(df_test, df_test[target])))"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"code","source":["from sklearn.metrics import classification_report\n\nprint(classification_report(df_test[target], pred))"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"code","source":["import graphviz\n\ndot_data = tree.export_graphviz(\n              pipeline.named_steps['classifier'], \n              out_file=None,\n              feature_names = categorical_feature_names + numerical_features,\n              class_names=[str(el) for el in pipeline.named_steps['classifier'].classes_],\n              filled=True, rounded=True,\n              special_characters=True)\n\ngraph = graphviz.Source(dot_data)\n# print out tree data since graph below fails in databricks.\nprint(graph.source)\n\n# simply call graph is supposed to render image in jupyter notebook, but doesn't work in databricks.\n# call graph.render(filename='/mnt/sandboxes/BillX/churn_tree.gv', view=True) reveals it trying to save\n# a copy of file, and then viewing it. In databricks, permission error occurs when saving the file for display.\n\ngraph\n"],"metadata":{},"outputs":[],"execution_count":22},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":23}],"metadata":{"name":"churn_decision_tree","notebookId":1672451382894229},"nbformat":4,"nbformat_minor":0}