{"cells":[{"cell_type":"markdown","source":["#Classification with Azure Databricks"],"metadata":{}},{"cell_type":"markdown","source":["###Initial configuration\n\nRun the next cell to import and configure the required modules."],"metadata":{}},{"cell_type":"code","source":["import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\nimport seaborn as sns\n\n%config InlineBackend.figure_format = 'retina' \n\nplt.style.use('seaborn-colorblind')\nplt.rcParams['axes.axisbelow'] = True\nmpl.rcParams['axes.titlesize'] = 20\nmpl.rcParams['axes.labelsize'] = 16\nmpl.rcParams['xtick.labelsize'] = 14\nmpl.rcParams['ytick.labelsize'] = 14\nmpl.rcParams['font.size'] = 16   # 10\n\nfrom sklearn import metrics\n\n# Ignore warnings from scikit-learn?\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\nfrom sklearn.exceptions import DataConversionWarning\nwarnings.filterwarnings(\"ignore\", category=DataConversionWarning)"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":["**IMPORTANT**'\n\nIf this is the first notebook you run from this lab, make sure you run the steps to import the data as indicated in the <a href=\"$./01 Model Training Selection Evaluation\">introductory notebook</a> of this lab.\n\nNext, let's load the dataset for this lab.\nBe sure to update the table name  \"usedcars\\_clean\\_#####\" (replace ##### to make the name unique within your environment)."],"metadata":{}},{"cell_type":"code","source":["df_clean = spark.sql(\"SELECT * FROM usedcars_clean_#####\")\ndf = df_clean.toPandas()\n\n# Shuffle the datarows randomly, to be sure that the ordering of rows is somewhat random:\ndf = df.sample(frac=1)"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":["Even if we got familiar with the dataset in the previous exercise, it is always a good idea to quickly inspect the data we have loaded. This acts as a fail-safe in case we by accident loaded the wrong dataset, and is also a good reference for the further development."],"metadata":{}},{"cell_type":"code","source":["df.info()"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":["If the previous output indicated that the Pandas dataframe now contains 1436 entries, we should be good to go. But let's also check a quick sample from the dataframe:"],"metadata":{}},{"cell_type":"code","source":["df.sample(3)"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":["###Supervised Learning - Classification introduction"],"metadata":{}},{"cell_type":"markdown","source":["In machine learning and statistics, classification is the problem of identifying to which of a set of categories (sub-populations) a new observation belongs, on the basis of a training set of data containing observations (or instances) whose category membership is known. \n\n**To get started we will define a classification problem by saying that \n*\"I only have $12'000. Given features describing a used car, can I afford it?***\n\nWe start by splitting our cars into cars that we can/cannot afford based on the age and mileage of the cars in our dataset. We take a look at the data, and then plot it as a scatterplot, where the red color represents cars that we cannot afford."],"metadata":{}},{"cell_type":"code","source":["limit = 12000\nprint('Price limit set for classification: ${}'.format(limit))\n\n# X contains ALL rows, but only the \"Age\" and \"KM\" columns:\nX = np.array(df[['Age', 'KM']])  # we only take the first two features.\n\n# We make `y` a vector (a list of numbers) that is 1 if we can afford a car, and 0 if not\ny = 1*np.array(df['Price']<limit)\n\n#Let's print the first rows of X and y, just so that we're sure of what we're dealing with:\nprint('X:\\n', X[0:10,:])\nprint('y:\\n', y[0:10])"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":["Looking at the above data, you'll see that `y` is `1` if we can afford a car (it typically is quite old, and has a high mileage). Let's make a scatterplot:"],"metadata":{}},{"cell_type":"code","source":["# Plot\nfig, ax = plt.subplots(figsize=(16, 8))\n\nplt.scatter(X[:, 0], X[:, 1], c=y, edgecolors='k', cmap=plt.cm.bwr_r, alpha=0.5)\nplt.xlabel('Age [months]')\nplt.ylabel('Driven distance [km]')\n\ndisplay(fig)\n"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":["That's it - is the plot understandable?\n\nSome of the models we will look at in the following require the input data to be scaled, so let's create a scaled version of the `X` we have already chosen. We do not have to do anything to `y` this time, since it is already just 0 or 1."],"metadata":{}},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":["###Classification - Logistic Regression"],"metadata":{}},{"cell_type":"markdown","source":["One of the workhorses for classification has for a long time been the method of **Logistic Regression**, also called the **logit or MaxEnt** classifier. It has confusing naming because it is a logistic function overlaid a linear regressor, where we normally use the so-called 50% probability line as a division between the classes we are interested in.\n\nLet's get started by creating the model, and train it on the scaled data we just prepared earlier."],"metadata":{}},{"cell_type":"code","source":["from sklearn import linear_model\n# Create a linear model for Logistic Regression\nclf = linear_model.LogisticRegression(C=1)\n\n# we create an instance of Neighbours Classifier and fit the data.\nclf.fit(X_scaled, y)"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":["With the classifier trained on all our data we are ready to visualize the results. Please run the following code cell without worrying about the (messy) contents, and proceed below."],"metadata":{}},{"cell_type":"code","source":["# This function DOES NOT HAVE TO BE UNDERSTOOD at this point :)\ndef plot_classification(clf, X, X_org, xlabel, y, ylabel, probplot):\n    '''\n    Take a classifier, scaled and original data as input, and show a very specialized plot\n    indicating the data, its class and the classifiers decision boundary.\n    '''\n    from matplotlib.colors import ListedColormap\n    # Plot the decision boundary. For that, we will assign a color to each\n    # point in the mesh [x_min, x_max]x[y_min, y_max].\n    h = 1000  # step size in the mesh\n    x_min, x_max = X[:, 0].min() - .0, X[:, 0].max() + .0\n    y_min, y_max = X[:, 1].min() - .0, X[:, 1].max() + .0\n    xx, yy = np.meshgrid(np.linspace(x_min, x_max, h), np.linspace(y_min, y_max, h))\n    # Plot the decision boundary. For that, we will assign a color to each\n    # point in the mesh [x_min, x_max]x[y_min, y_max].\n    predict_proba = False\n    if probplot:\n        if hasattr(clf, \"predict_proba\"):\n            Z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]*100\n            predict_proba = True\n        elif hasattr(clf, \"decision_function\"):\n            Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])\n        else:\n            Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n    else:\n        Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n    # Put the result into a color plot\n    cm_bright = ListedColormap(['#FF0000', '#0000FF'])\n    Z = Z.reshape(xx.shape)\n    # Create the figure\n    fig, ax = plt.subplots(1, figsize=(16, 8))\n    # Re-do the mesh in original coordinates, as a hack to show the original axes\n    x_min, x_max = X_org[:, 0].min() - .0, X_org[:, 0].max() + .0\n    y_min, y_max = X_org[:, 1].min() - .0, X_org[:, 1].max() + .0\n    xx, yy = np.meshgrid(np.linspace(x_min, x_max, h), np.linspace(y_min, y_max, h))\n    # Plot the decision boundary or the decision probability function as a background\n    plt.contourf(xx, yy, Z, cmap=plt.cm.RdBu, alpha=0.8)\n    if predict_proba:\n        plt.colorbar()\n    # Plot also the training points\n    ax.scatter(X_org[:, 0], X_org[:, 1], c=y, edgecolors='k', cmap=cm_bright, alpha=0.6)\n    # Set the labels, view-limits and show the plot\n    ax.set_xlabel(xlabel)\n    ax.set_ylabel(ylabel)\n    ax.set_xlim(xx.min(), xx.max())\n    ax.set_ylim(yy.min(), yy.max())\n    display(fig)"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"markdown","source":["Let's use the plotting function defined above to show us **where in the two-dimensional age-mileage-space the classifier has decided to draw its decision boundary**. We'll explain a bit more after the plot."],"metadata":{}},{"cell_type":"code","source":["plot_classification(clf, X_scaled, X, 'Age [Months]', y, 'Mileage [KM]', False)"],"metadata":{},"outputs":[],"execution_count":23},{"cell_type":"markdown","source":["The background color of this plot is now showing what category the classifier will give as output, if the input is provided as a used car's age and mileage (red means can't afford, blue means can afford).\n\n**Questions:**\n- If we provide the now trained classifier with the following car information: [Age=40, KM=100000]\n    - Will the model predict that we can afford that car?\n- Can we take the classifier model we now have trained and assess its performance? Why not? (Hint: Train/Test datasets...)\n\nMost models that try to classify something also report their confidence in their classifications. These confidence numbers can be a bit difficult to interpret correctly, but they still provide valuable information. Run the following code cell to show in colors how certain the classifier is in predicting whether we can afford a used car."],"metadata":{}},{"cell_type":"code","source":["plot_classification(clf, X_scaled, X, 'Age [Months]', y, 'Mileage [KM]', True)"],"metadata":{},"outputs":[],"execution_count":25},{"cell_type":"markdown","source":["Can you now see the way this method works? It has created a third dimension, in this plot the z-axis coming out of your screen, and here it has fitted a function that looks like the \"Niagra falls\" - a hill with a non-linear slope, but with a straight edge."],"metadata":{}},{"cell_type":"markdown","source":["###Classification: Support Vector Machines"],"metadata":{}},{"cell_type":"markdown","source":["While we are looking at simplified visuals over how a classifier might make its decisions, when given all the data we have, let's also look at a not-so-linear example. The following cell shows a **Support Vector Machine Classifier** in action, based on the Gaussian-like *Radial Basis Function (RBF)* kernel. These models have a lot of variations and tunable parameters, but we will not go into these details here.\n\n\n<div class=\"alert alert-block alert-info\">\n\n  If you have time, or for later:<br>\nHere is a link to the scikit-learn overview article on Support Vector Machines: [(click here)](http://scikit-learn.org/stable/modules/svm.html)\n</div>"],"metadata":{}},{"cell_type":"code","source":["# Re-prepare the inputs, in case we have run the cells in this notebook out-of-order:\nX = np.array(df[['Age', 'KM']])  # we only take the first two features.\nX_scaled = StandardScaler().fit_transform(X) # Use scaled/normalized X-values\ny = 1*np.array(df['Price']<limit)"],"metadata":{},"outputs":[],"execution_count":29},{"cell_type":"code","source":["### Running this cell might take some 20 seconds ###\nfrom sklearn import svm\n\n# Create a Support Vector Machine Classifier with a Radial Basis Function (RBF) kernel:\nclf = svm.SVC(kernel='rbf', C=1, gamma=2)\n\n# Fit the data.\nclf.fit(X_scaled, y)\n\n# Plot the datapoints, colored by category, with a background showing a not-explained measure for the certainty\nplot_classification(clf, X_scaled, X, 'Age [Months]', y, 'Mileage [KM]', True)"],"metadata":{},"outputs":[],"execution_count":30},{"cell_type":"markdown","source":["Even in two dimensions it is clear that methods like this SVC with an RBF kernel can be powerful tools with less limitations than the standard logistic regression we saw earlier. (However: There are many ways to make models more complicated and able to fit non-linear data behaviour, feature engineering is one of them. There is a jungle of models out there, and it can be very challenging choosing the right ones.)\n\n\nPS: In terms of the \"Niagra falls\" third dimension explanation we gave above, this method kindof makes three-dimensional Gaussian \"hats\" and put them everywhere in the plot above in an overlapping fashion."],"metadata":{}},{"cell_type":"markdown","source":["###Classification - Decision Tree Classifier"],"metadata":{}},{"cell_type":"markdown","source":["The familiar decision tree is very popular for working with classification problems, both two-class and multi-class types. It is fast and typically performs decently, but it is the other models that are *based on multiple decision trees*, **Random Forest, boosted trees, XDGBoost etc...** that are common in ML today.\n\nSingle decision trees are however popular still, partly because we easily can plot them in full and inspect them. Please run the code below, have a look at the plot and see if you can answer the questions below it."],"metadata":{}},{"cell_type":"markdown","source":["**Overfitting**"],"metadata":{}},{"cell_type":"code","source":["# Re-prepare the inputs, in case we have run the cells in this notebook out-of-order:\nX = np.array(df[['Age', 'KM']])  # we only take the first two features.\ny = 1*np.array(df['Price']<limit)\n\nfrom sklearn import tree\n\n# Create a Decicion Tree Classifier with default settings:\nclf = tree.DecisionTreeClassifier()\n\n\n# Fit the data. NB: Now we do NOT use the scaled data. We could, but it is not necessary with decision trees!\nclf.fit(X, y)\n\n# Plot the datapoints, colored by category, with a background showing how it would classify a datapoint in that coordinate\nplot_classification(clf, X, X, 'Age [Months]', y, 'Mileage [KM]', False)"],"metadata":{},"outputs":[],"execution_count":35},{"cell_type":"markdown","source":["A decision tree classifier with default settings has no limits on the depth of the tree. Take a close look at the figure above, and try to answer the following questions.\n\n**Questions:**\n- Does the classifier seem to do a good job in predicting the right class for each datapoint?\n- This classifier was trained on all the data available. Is there a way to judge its performance?\n- Do you think the decision boundaries shown in the figure are representative in answering what age-mileage we have to accept in order to afford a car?\n- The above result is a good example of *overfitting*. Just to re-cap a little from the previous lab: What does this mean? Is this a good thing?\n- What would you do with the classifier in order to reduce this overfitting?\n\n**Exercise:**\nAdjust the maximum depth of the tree (hint: the parameter name is max_depth).\n\n\nDid this make the concept of overfitting more clear to you? We'd love to hear your feedback. And of course, ask us if you have any questions."],"metadata":{}},{"cell_type":"markdown","source":["###Classification performance evaluation"],"metadata":{}},{"cell_type":"markdown","source":["We will now have a quick look at performance evaluation for classifiers. Until now we have not done a `train-test-split`, making it impossible to assess the performance of our classifier. We will therefore do the split from now on.\n\nPerformance metrics like **Precision, Recall and F1-score** can be a bit tricky getting used to, but see if you can run the code below and get some information from the \"classification report\"."],"metadata":{}},{"cell_type":"markdown","source":["**Without cross-validation**"],"metadata":{}},{"cell_type":"code","source":["# X contains ALL rows, but only the \"Age\" and \"KM\" columns:\nX = np.array(df[['Age', 'KM']])  # we only take the first two features.\nX_scaled = StandardScaler().fit_transform(X)\n\n# We make `y` a vector (a list of numbers) that is 1 if we can afford a car, and 0 if not\ny = 1*np.array(df['Price']<limit)\n\nfrom sklearn.model_selection import train_test_split\n\n# Use the regular train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8)\n\n# Create a classifier model:\nclf = tree.DecisionTreeClassifier(max_depth=3)\n\n# we create an instance of Neighbours Classifier and fit the data.\nclf.fit(X_train, y_train)\n\nfrom sklearn.metrics import classification_report\n\n# Get predictions from the model, from the test-dataset:\ny_pred = clf.predict(X_test)\n\n# Print a classification report, using sklearn:\nprint(\"Classification report:\\n%s\\n\"\n      % (classification_report(y_test, y_pred, target_names=['Not Affordable', 'Affordable'])))"],"metadata":{},"outputs":[],"execution_count":40},{"cell_type":"markdown","source":["What do you think about the scores? They are overall very good, but notice that the category \"Affordable\" is quite underrepresented. It is often smart to let the model compensate for this inbalance, but we will not look at this in this lab.\n\nLet's have a look at the visual side of the classification, showing the \"confidence\" of the classifier on a percentage scale:"],"metadata":{}},{"cell_type":"code","source":["plot_classification(clf, X, X, 'Age [Months]', y, 'Mileage [KM]', True)"],"metadata":{},"outputs":[],"execution_count":42},{"cell_type":"markdown","source":["We will now use the test-dataset with the model to get some scoring data that can be used for some insight into the classification evaluation. First we make the model give us uncertainty estimates for what category it predicts for all the data in the test-dataset:"],"metadata":{}},{"cell_type":"code","source":["# y_score = clf.decision_function(df_test_scaled[features])\ny_score = clf.predict_proba(X_test)\n\n# Do some necessary imports for this section:\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.metrics import precision_recall_curve\nfrom sklearn.metrics import average_precision_score\n\naverage_precision = average_precision_score(y_test, y_pred)\nprint('Average precision-recall score: {0:0.2f}'.format(average_precision))"],"metadata":{},"outputs":[],"execution_count":44},{"cell_type":"markdown","source":["We can now plot the **Precision-Recall curve**, another insight into our classification performance. It shows how precision in the classifications develops as a function of the recall score, and can for some datasets tell us about the data quality, model parameter consequences and much more. For now we'll have a look, and then move on."],"metadata":{}},{"cell_type":"code","source":["# Get the precision and recall scores that are necessary:\nprecision, recall, _ = precision_recall_curve(y_test, y_score[:,1])\n\n# Make the plot:\nfig, ax = plt.subplots(figsize=(12,6))\nplt.step(recall, precision, alpha=0.2, where='post')\nplt.fill_between(recall, precision, step='post', alpha=0.2)\nax.set_xlabel('Recall')\nax.set_ylabel('Precision')\nax.set_title('2-class Precision-Recall curve: AP={0:0.2f}'.format(average_precision))\n\ndisplay(fig)"],"metadata":{},"outputs":[],"execution_count":46},{"cell_type":"markdown","source":["Receiver-Operative-Characteristic-curves (ROC-curves), and the area under them (ROC AUC), are also famous instruments we can use in getting insight into classification data, models and algorithms.\n[Some info on ROC on sklearn - click here if you have time.](http://scikit-learn.org/stable/modules/model_evaluation.html#receiver-operating-characteristic-roc)"],"metadata":{}},{"cell_type":"code","source":["# Get the ROC data:\nfpr, tpr, _ = roc_curve(y_test, y_score[:,1])\nroc_auc = auc(fpr, tpr)\n\n# Plot a standard ROC plot:\nfig, ax = plt.subplots(figsize=(6,6))\nax.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)'%roc_auc)\nax.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\nax.set_xlabel('False Positive Rate')\nax.set_ylabel('True Positive Rate')\nax.set_title('Receiver Operative Characteristic')\nplt.legend(loc='lower right')\ndisplay(fig)"],"metadata":{},"outputs":[],"execution_count":48},{"cell_type":"markdown","source":["After looking at some (not fully explained) performance scores, it's time to look at the actual tree and its decisions itself. The following code will install and import a multi-purpose library called **ELI5**, and then plot the decision tree with some options."],"metadata":{}},{"cell_type":"code","source":["import eli5\n\nx = eli5.show_weights(clf, feature_names=['Age', 'KM'], target_names=['Affordable', 'NOT Affordable'],\n                     filled=True)\n\ndisplayHTML(\"<html><body>\" + x.data + \"</body></html>\")"],"metadata":{},"outputs":[],"execution_count":50},{"cell_type":"markdown","source":["Quite nice! Can you understand the essentials of the tree? It always puts \"True\" results to the left of a split. The top of each box shows the evaluation it runs to make the decision, and the color and bottommost text in each box tells us whether the model will predict that we can afford a car, given information about age and mileage of a car.\n\nOn the top left we see a nice feature of the ELI5-library (search for the library online if you have time!), namely a summary of what *weight* the tree puts on a given feature. In this case it tells us that age is MUCH more important than mileage in deciding whether we can afford a car!"],"metadata":{}},{"cell_type":"code","source":["chosen_datapoint = X_test[3]\nprint('The chosen datapoint from X_test is:', chosen_datapoint)\nprint('\\nOutput from ELI5:')\nx = eli5.show_prediction(clf, X_test[3], show=eli5.formatters.fields.WEIGHTS, show_feature_values=True)\ndisplayHTML(\"<html><body>\" + x.data + \"</body></html>\")"],"metadata":{},"outputs":[],"execution_count":52},{"cell_type":"markdown","source":["Finally, we use ELI5 to try to \"explain\" to us WHY a given datapoint (a car: its age and mileage) was put in a certain category. Can you interpret its output? What does \"``<BIAS>``\" mean do you think?"],"metadata":{}},{"cell_type":"markdown","source":["**Using more features (no cross-validation)**"],"metadata":{}},{"cell_type":"markdown","source":["We will now try to \n1. Use more features from the dataset in our model\n- Use a \"random forest\" model\n- Extract the feature importance from the model, an often valuable piece of information\n\nSee if you can follow the code below. Are you happy with the score? We do this in a simplified manner, without cross-validation. Can you trust the results? It is an open question - we don't know the answer. Maybe we are overfitting our model? What plots would you plot to get some insight into this, and other \"traps\" the model might have fallen into?"],"metadata":{}},{"cell_type":"code","source":["df_ohe = df.copy(deep=True)\ndf_ohe['FuelType'] = df_ohe['FuelType'].astype('category')\ndf_ohe['MetColor'] = df_ohe['MetColor'].astype('category')\ndf_ohe['Automatic'] = df_ohe['Automatic'].astype('category')\ndf_ohe['Doors'] = df_ohe['Doors'].astype('category')\ndf_ohe = pd.get_dummies(df_ohe)\n\ndf_ohe.sample()\n\nlimit = 12000\n\nml_features_in_use = ['Age', 'KM', 'Weight', 'HP', 'CC', 'FuelType_cng', 'FuelType_diesel', 'FuelType_petrol']\nX = np.array(df_ohe[ml_features_in_use])\ny = 1*np.array(df['Price']<limit)\n\nprint('Price limit set for classification: ${}'.format(limit))\nprint('Using the following features: ', ml_features_in_use)\n\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Use the regular train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8)\n\n# Create a model:\nclf = RandomForestClassifier(n_estimators=20, max_depth=3)\n\n# we create an instance of Neighbours Classifier and fit the data.\nclf.fit(X_train, y_train)\n\n# Get predictions from the model, from the test-dataset:\ny_pred = clf.predict(X_test)\n\n# Print a classification report, using sklearn:\nprint(\"Classification report:\\n%s\\n\"\n      % (classification_report(y_test, y_pred, target_names=['Not Affordable', 'Affordable'])))"],"metadata":{},"outputs":[],"execution_count":56},{"cell_type":"markdown","source":["**Investigate feature importances**"],"metadata":{}},{"cell_type":"markdown","source":["We are at the end of the modelling and evaluation lab. We end with a great little feature of some models, and especially decision trees and their cousins (random forest etc.): Checking the \"variable importance\". We will not go into detail, but check out the code below, and see if you agree with what the model tells us are the \"most important features\" for deciding if we can afford a car with a set of properties.\n\nFeel free to go back and change the model, or add/remove features. `Number of estimators` and `depth` can have a big impact on the feature imporances, since they strongly affect the model. If you have time, add age^2 and other engineered features, and see if the model thinks these additions are \"important\"!"],"metadata":{}},{"cell_type":"code","source":["clf.feature_importances_"],"metadata":{},"outputs":[],"execution_count":59},{"cell_type":"code","source":["def plot_model_var_imp( model, X):\n    imp = pd.DataFrame(\n        model.feature_importances_ ,\n        columns = ['Importance'] ,\n        index = X.columns\n    )\n    imp = imp.sort_values( [ 'Importance' ] , ascending = True )\n    \n    fig, ax = plt.subplots(figsize=(12,6))\n    imp['Importance'].plot(kind='barh')\n    display(fig)"],"metadata":{},"outputs":[],"execution_count":60},{"cell_type":"code","source":["plot_model_var_imp(clf, df_ohe[ml_features_in_use])"],"metadata":{},"outputs":[],"execution_count":61},{"cell_type":"markdown","source":["**Classification using part-cross-validation**\n\nFor completeness, we also do the classification using cross-validation (with all the data, as we have done some times before). Can you see that the scores can get a bit confusing in their naming? This is quite often the case.. The code below works well, but some parts of the scoring is missing when we compare the two outputs. See if you can match up the results from the cross-validated 5 runs and the \"report\", if you have time."],"metadata":{}},{"cell_type":"code","source":["# Import the cross-validation function:\nfrom sklearn.model_selection import cross_validate, cross_val_predict\n\n# Shuffle the rows of the dataframe, since the train_test_split function will not do it for us:\ndf = df.sample(frac=1)\n\nlimit = 12000\nprint('Price limit set for classification: ${}'.format(limit))\n\n# Select the columns/features from the Pandas dataframe that we want to use in the model:\nX = np.array(df[['Age', 'KM']])  # we only take the first two features.\ny = 1*np.array(df['Price']>limit)\n\n# Create a linear regression model that we can train:\nclf = tree.DecisionTreeClassifier(max_depth=3)\n\n# Print some information about the linear model and its parameters:\nprint(clf)\n\n# Train the model using CV and multiple scoring on the data we have prepared:\ncv_results = cross_validate(clf, # Provide our model to the CV-function\n                            X, # Provide all the features (in real life only the training-data)\n                            y, # Provide all the \"correct answers\" (in real life only the training-data)\n                            scoring=('f1', 'precision', 'recall', 'accuracy'), \n                            cv=5 # Cross-validate using 5-fold (K-Fold method) cross-validation splits\n                           )\n\nF1_pos   = cv_results['test_f1']\nP_pos   = cv_results['test_precision']\nR_pos   = cv_results['test_recall']\nA   = cv_results['test_accuracy']\n\nprint('\\n-------------- Scores ---------------')\nprint('Average F1:\\t {:.2f} (+/- {:.2f})'.format(F1_pos.mean(), F1_pos.std()))\nprint('Average Precision (y positive):\\t {:.2f} (+/- {:.2f})'.format(P_pos.mean(), P_pos.std()))\nprint('Average Recall (y positive):\\t {:.2f} (+/- {:.2f})'.format(R_pos.mean(), R_pos.std()))\nprint('Average Accuracy:\\t {:.2f} (+/- {:.2f})'.format(A.mean(), A.std()))\n\n# Get price-predictions for all data as test-data using cross_val_predict:\ny_pred = cross_val_predict(clf, \n                            X,\n                            y,\n                            cv=5\n                           )\n\nfrom sklearn.metrics import classification_report\nprint(\"Classification report:\\n%s\\n\"\n      % (classification_report(y, y_pred, target_names=['Not Affordable', 'Affordable'])))"],"metadata":{},"outputs":[],"execution_count":63},{"cell_type":"markdown","source":["### Comparison of several scikit-learn classifiers"],"metadata":{}},{"cell_type":"markdown","source":["If you have time: The following code is from sklearn's website. If you are interested and have time, it is some fun code to play around with in order to build some intuition for how the most popular models work and react to different parameters and data. Enjoy!"],"metadata":{}},{"cell_type":"code","source":["# Code source: Gaël Varoquaux\n#              Andreas Müller\n# Modified for documentation by Jaques Grobler\n# License: BSD 3 clause\nmpl.rcParams.update(mpl.rcParamsDefault)\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import ListedColormap\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.datasets import make_moons, make_circles, make_classification\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.gaussian_process import GaussianProcessClassifier\nfrom sklearn.gaussian_process.kernels import RBF\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n\nh = .02  # step size in the mesh\n\nnames = [\"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\", \"Gaussian Process\",\n         \"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\",\n         \"Naive Bayes\", \"QDA\"]\n\nclassifiers = [\n    KNeighborsClassifier(3),\n    SVC(kernel=\"linear\", C=0.025),\n    SVC(gamma=2, C=1),\n    GaussianProcessClassifier(1.0 * RBF(1.0)),\n    DecisionTreeClassifier(max_depth=5),\n    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n    MLPClassifier(alpha=1),\n    AdaBoostClassifier(),\n    GaussianNB(),\n    QuadraticDiscriminantAnalysis()]\n\nX, y = make_classification(n_features=2, n_redundant=0, n_informative=2,\n                           random_state=1, n_clusters_per_class=1)\nrng = np.random.RandomState(2)\nX += 2 * rng.uniform(size=X.shape)\nlinearly_separable = (X, y)\n\ndatasets = [make_moons(noise=0.3, random_state=0),\n            make_circles(noise=0.2, factor=0.5, random_state=1),\n            linearly_separable\n            ]\n\n\nfigure, ax = plt.subplots(len(datasets), len(classifiers) + 1, figsize=(27, 9))\n\n# iterate over datasets\nfor ds_cnt, ds in enumerate(datasets):\n    print('ds_cnt: {0}'.format(ds_cnt))\n    # preprocess dataset, split into training and test part\n    X, y = ds\n    X = StandardScaler().fit_transform(X)\n    X_train, X_test, y_train, y_test = \\\n        train_test_split(X, y, test_size=.4, random_state=42)\n\n    x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n    y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n                         np.arange(y_min, y_max, h))\n\n    # just plot the dataset first\n    cm = plt.cm.RdBu\n    cm_bright = ListedColormap(['#FF0000', '#0000FF'])\n\n    if ds_cnt == 0:\n        ax[ds_cnt,0].set_title(\"Input data\")\n    # Plot the training points\n    ax[ds_cnt,0].scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright,\n               edgecolors='k')\n    # and testing points\n    ax[ds_cnt,0].scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=cm_bright, alpha=0.6,\n               edgecolors='k')\n    ax[ds_cnt,0].set_xlim(xx.min(), xx.max())\n    ax[ds_cnt,0].set_ylim(yy.min(), yy.max())\n    ax[ds_cnt,0].set_xticks(())\n    ax[ds_cnt,0].set_yticks(())\n    \n    i = 1\n    # iterate over classifiers\n    for name, clf in zip(names, classifiers):\n        \n        clf.fit(X_train, y_train)\n        score = clf.score(X_test, y_test)\n\n        # Plot the decision boundary. For that, we will assign a color to each\n        # point in the mesh [x_min, x_max]x[y_min, y_max].\n        if hasattr(clf, \"decision_function\"):\n            Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])\n        else:\n            Z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n\n        # Put the result into a color plot\n        Z = Z.reshape(xx.shape)\n        \n        ax[ds_cnt,i].contourf(xx, yy, Z, cmap=cm, alpha=.8)\n\n        # Plot also the training points\n        ax[ds_cnt,i].scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright,\n                   edgecolors='k')\n        # and testing points\n        ax[ds_cnt,i].scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=cm_bright,\n                   edgecolors='k', alpha=0.6)\n\n        ax[ds_cnt,i].set_xlim(xx.min(), xx.max())\n        ax[ds_cnt,i].set_ylim(yy.min(), yy.max())\n        ax[ds_cnt,i].set_xticks(())\n        ax[ds_cnt,i].set_yticks(())\n        if ds_cnt == 0:\n            ax[ds_cnt,i].set_title(name)\n        ax[ds_cnt,i].text(xx.max() - .3, yy.min() + .3, ('%.2f' % score).lstrip('0'),\n                size=15, horizontalalignment='right')\n        \n        i += 1\n\nplt.tight_layout()\ndisplay(figure)"],"metadata":{},"outputs":[],"execution_count":66},{"cell_type":"markdown","source":["You can now move to the next notebook in the lab - <a href=\"$./04 Advanced Regression with Azure Databricks\">Advanced Regression with Azure Databricks</a>."],"metadata":{}}],"metadata":{"name":"03 Classification with Azure Databricks","notebookId":2793193203916755},"nbformat":4,"nbformat_minor":0}