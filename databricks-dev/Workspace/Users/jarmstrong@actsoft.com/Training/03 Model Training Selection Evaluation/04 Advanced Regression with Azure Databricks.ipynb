{"cells":[{"cell_type":"markdown","source":["#Advanced Regression with Azure Databricks"],"metadata":{}},{"cell_type":"markdown","source":["###Initial configuration"],"metadata":{}},{"cell_type":"markdown","source":["In this section we perform some imports and initial configurations to make sure everything is properly prepared for the next steps.\n\nWe are also using one of the popular Machine Learning modules in the data science world, scikit-learn.\n\n\n![](http://scikit-learn.org/stable/_static/scikit-learn-logo-small.png)\n**Scikit-learn is a widely used library for Machine Learning in Python**\n- Contains simple and efficient tools for data mining and data analysis\n- Accessible to everybody, and reusable in various contexts\n- Built on NumPy, SciPy, and matplotlib (the \"big three\")\n- Open source, commercially usable - BSD license\n\nRun the next cell to import and configure the required modules."],"metadata":{}},{"cell_type":"code","source":["# Do the most standard imports for DS:\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\nimport seaborn as sns\n\n# We all have high-resolution displays now. Make sure we exploit that.\n%config InlineBackend.figure_format = 'retina' \n\n# Adjust some colors and fonts to make our plots easier to navitate and understand:\nplt.style.use('seaborn-colorblind')\nplt.rcParams['axes.axisbelow'] = True\nmpl.rcParams['axes.titlesize'] = 20\nmpl.rcParams['axes.labelsize'] = 16\nmpl.rcParams['xtick.labelsize'] = 14\nmpl.rcParams['ytick.labelsize'] = 14\nmpl.rcParams['font.size'] = 16   # 10\nmpl.rcParams['legend.fontsize'] = 14\n# Tell Pandas to only show us two decimals\npd.set_option('precision',2)\n\n# Some necessary sklearn imports that we will need later\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression, SGDRegressor\nfrom sklearn import metrics\n\n### Optional code, but quite useful for this lab context! ###\n# Ignore warnings from scikit-learn?\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\nfrom sklearn.exceptions import DataConversionWarning\nwarnings.filterwarnings(\"ignore\", category=DataConversionWarning)"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":["**IMPORTANT**'\n\nIf this is the first notebook you run from this lab, make sure you run the steps to import the data as indicated in the <a href=\"$./01 Model Training Selection Evaluation\">introductory notebook</a> of this lab.\n\nNext, let's load the dataset for this lab.\nBe sure to update the table name  \"usedcars\\_clean\\_#####\" (replace ##### to make the name unique within your environment)."],"metadata":{}},{"cell_type":"code","source":["df_clean = spark.sql(\"SELECT * FROM usedcars_clean_#####\")\ndf = df_clean.toPandas()"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":["### Polynomial Regression"],"metadata":{}},{"cell_type":"markdown","source":["**First, a quick overview over polynomial regression**. Feel free to skip this if you want - the important part is that we can use **feature engineering** to add polynomials of features we already have in order to let the model lean non-linear behaviour in the features. This way, we **make a more advanced model out of a simple one**. This is an often-used \"trick\" in ML.\n\n**Quick recap of linear and polynomial regression**:\n\n\nGiven \\\\( \\mathbf{x} \\\\), a column vector, and \\\\( \\mathbf{y} \\\\), the target vector, you can perform polynomial regression by appending polynomials of \\\\( \\mathbf{x} \\\\). For example, consider if \n\n$$ \\mathbf{x} = \\begin{bmatrix} 2 \\\\\\\\[0.3em] -1 \\\\\\\\[0.1em] \\frac{1}{3} \\end{bmatrix} $$\n\nUsing just this vector in linear regression implies the model:\n\n$$ y = \\alpha_1 x $$ \n\nWe can add columns that are powers of the vector above, which represent adding polynomials to the regression. Below we show this for polynomials up to power 3:\n\n$$ \\mathbf{x} = \\begin{bmatrix} 2 & 4 & 8 \\\\\\\\[0.3em] -1 & 1 & -1 \\\\\\\\[0.1em] \\frac{1}{3} & \\frac{1}{3^2} & \\frac{1}{3^3} \\end{bmatrix} $$\n\nThis is our new data matrix that we use in sklearn's linear regression, and it represents the model:\n\n$$ y = \\alpha_1 x + \\alpha_2x^2 + \\alpha_3x^3$$"],"metadata":{}},{"cell_type":"markdown","source":["**Add \"Age squared\" as feature**\n\nLet's add the squared of the `Age` to our dataset:"],"metadata":{}},{"cell_type":"code","source":["# Make a copy of our \"original\" data, so that we avoid later confusion\ndf_poly = df.copy(deep=True)\n# When we do a mathematical operation on a Pandas Series object, like the \"Age\"-column, Pandas will automatically do the operation on each element in that Series (since it is build on NumPy, and normally acts as NumPy would)\ndf_poly['Age**2'] = df['Age']**2"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":["Our new dataframe `df_poly` should now contain a column with Age squared. Let's inspect and see if that is true for 3 randomly sampled rows from the dataframe:"],"metadata":{}},{"cell_type":"code","source":["df_poly.sample(3)"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":["Good! We can now use the \"`Age**2`\"-column in training/fitting our linear regression model just like we would any other feature:"],"metadata":{}},{"cell_type":"code","source":["# Import the cross-validation function:\nfrom sklearn.model_selection import cross_validate, cross_val_predict\n\n# Shuffle the rows of the dataframe, since the train_test_split function will not do it for us:\ndf_poly = df_poly.sample(frac=1)\n# Select the columns/features from the Pandas dataframe that we want to use in the model:\nX_poly = np.array(df_poly[['Age', 'Age**2']])\n# X_poly = np.array(df_poly[['Age']])\ny_poly = np.array(df_poly['Price'])\n\n# Create a linear regression model that we can train:\nmodel = LinearRegression()\n# Print some information about the linear model and its parameters:\nprint(model)\n\n# Train the model using CV and multiple scoring on the data we have prepared:\ncv_results = cross_validate(model, # Provide our model to the CV-function\n                            X_poly, # Provide all the features (in real life only the training-data)\n                            y_poly, # Provide all the \"correct answers\" (in real life only the training-data)\n                            scoring=('r2', 'neg_mean_squared_error', 'neg_mean_absolute_error'), \n                            cv=5 # Cross-validate using 5-fold (K-Fold method) cross-validation splits\n                           )\n\nMAE  = -cv_results['test_neg_mean_absolute_error']\nRMSE = np.sqrt(-cv_results['test_neg_mean_squared_error'])\nR2   = cv_results['test_r2']\n\nprint('MAE:', MAE)\nprint('RMSE:', RMSE)\nprint('R2:', R2)\n\nprint('Average R^2:\\t {:.2f} (+/- {:.2f})'.format(R2.mean(), R2.std()))\nprint('Average MAE:\\t {:.2f} (+/- {:.2f})'.format(MAE.mean(), MAE.std()))\nprint('Average RMSE:\\t {:.2f} (+/- {:.2f})'.format(RMSE.mean(), RMSE.std()))"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":["**Questions:**\n- How are the results we got now relative to what we got earlier, when we only used `Age`? \n- Do you agree that it is easier to compare these performance scores to the ones we got previously, now that we use cross-validation to get more \"stable\" performance scores?\n\nThis time we also want to make predictions using our model, so that we can inspect our results visually. We then use the function `cross_cal_predict`, which first trains the model just like the `cross_validate` function does, but then also stores what price (`y`) the 5 different models (trained on 5 different splits of the data, 5-Fold) predicted for the test data that was not seen by the models when they were trained.\n\nThe end result is that we get predictions for all of our datapoints in the dataframe, from 5 different examples of our model. We then plot the \"price vs. age\" for the original data in blue, and the predicted data from the polynomial model in red:"],"metadata":{}},{"cell_type":"code","source":["y_pred = cross_val_predict(model, \n                            X_poly,\n                            y_poly,\n                            cv=5\n                           )\n\nfig, ax = plt.subplots(figsize= (15, 6))\n\nax.scatter(X_poly[:,0], y_poly)\nax.plot(X_poly[:,0], y_pred, 'ro')\nplt.title('Price of used cars as a function of age')\nplt.ylabel('Price [$]')\nplt.xlabel('Age [Months]')\nplt.grid()\ndisplay(fig)"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":["Did this look like you expected? Can you see that the model, even if it is a linear model, learned to predict values that partially follow a second-degree polynomial? How and why did this work, and how is this possible? Feel free to ask us, or move on if you are short om time.\n\nIf you have time later: Try to *remove* the original feature `Age` from the input to the model. How does it score now? What does this tell us?\n\n**Adding an engineered feature like we just did is very powerful in ML, and is often absolutely necessary in order to achieve good results.**"],"metadata":{}},{"cell_type":"markdown","source":["**Summary so far...**\n\nSo far...\n- We have looked at linear regression, and how it works\n- We have tried linear regression with only one feature (so-called *simple* linear regression) and with several features\n- We have investigated how an SGD regressor was trained through iterations, and we learned that this concept is at the heart of most ML algorithms\n- We have tried **engineering a new polynomial feature** in our dataset, and have used this in the linear regression model to do *polynomial regression*\n\nNot bad. Training or building a model that can represent the data we have, like we have done already, is at the heart of Machine Learning. The number of techniques that are available to us can, however, be quite daunting - there are a huge number of models and techniques available to us in libraries, but we need to learn how to use them in order for them to be useful. \n\nWhat we have seen so far have been some examples of linear regression models. These are part of a larger family called **Generalized Linear Models (GLM)**, where they all have in common that they try to find the (multi-dimensional) \"line\" that fits our data the best in some way.\n[This page (click here)](http://scikit-learn.org/stable/modules/linear_model.html) gives a good overview over the GLMs in scikit-learn.\n\nWe will now move on to some \"more exciting\" models."],"metadata":{}},{"cell_type":"markdown","source":["### Regression - Decision Trees"],"metadata":{}},{"cell_type":"markdown","source":["Decision trees are enormously poplular in ML, for many reasons. We will look at them a bit more closely when we start looking at classification, but for now, see how easy it is to run our now familiar code but using a decision tree instead. \n\nFor later, if you are interested:\n[Read more about Decision Trees in the excellent overview given by scikit-learn](http://scikit-learn.org/stable/modules/tree.html)"],"metadata":{}},{"cell_type":"code","source":["from sklearn import tree\ndf.sample()\n\n# Shuffle the rows of the dataframe, since the train_test_split function will not do it for us:\ndf = df.sample(frac=1)\n# Select the columns/features from the Pandas dataframe that we want to use in the model:\nX = np.array(df[['Age', 'KM', 'Weight']])\n# X = np.array(df[['Age']])\ny = np.array(df['Price'])\n\n# Create a linear regression model that we can train:\nmodel = tree.DecisionTreeRegressor(criterion='mse', max_depth=1)\n# Print some information about the linear model and its parameters:\nprint(model)\n\n# Train the model using CV and multiple scoring on the data we have prepared:\ncv_results = cross_validate(model, # Provide our model to the CV-function\n                            X, # Provide all the features (in real life only the training-data)\n                            y, # Provide all the \"correct answers\" (in real life only the training-data)\n                            scoring=('r2', 'neg_mean_squared_error', 'neg_mean_absolute_error'), \n                            cv=5 # Cross-validate using 5-fold (K-Fold method) cross-validation splits\n                           )\n\nMAE  = -cv_results['test_neg_mean_absolute_error']\nRMSE = np.sqrt(-cv_results['test_neg_mean_squared_error'])\nR2   = cv_results['test_r2']\n\nprint('\\n-------------- Scores ---------------')\nprint('Average R^2:\\t {:.2f} (+/- {:.2f})'.format(R2.mean(), R2.std()))\nprint('Average MAE:\\t {:.2f} (+/- {:.2f})'.format(MAE.mean(), MAE.std()))\nprint('Average RMSE:\\t {:.2f} (+/- {:.2f})'.format(RMSE.mean(), RMSE.std()))"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"markdown","source":["Not a good score, right? That is not surprising, **since the tree is currently only allowed to make a single decision!** Try changing the argument `max_depth`, and see if you can find the optimal number below 20.\n\nThe decision tree is fast and simple to use, and it works with no scaling of the input. \nHowever, we will later see that it must be used with care -- the results above are not the whole story."],"metadata":{}},{"cell_type":"markdown","source":["### Regression (and pipelines) - Support Vector Machines (SVM)**"],"metadata":{}},{"cell_type":"markdown","source":["We continue with the same code as previously, but now with a Linear Support Vector Machine: a very popular go-to model for both regression and classification. Let's see what we get with the following code:"],"metadata":{}},{"cell_type":"code","source":["from sklearn import svm\n# Shuffle the rows of the dataframe, since the train_test_split function will not do it for us:\ndf = df.sample(frac=1)\n# Select the columns/features from the Pandas dataframe that we want to use in the model:\nX = np.array(df[['Age', 'KM', 'Weight']])\n# X = np.array(df[['Age']])\ny = np.array(df['Price'])\n\n# Create a linear regression model that we can train:\nmodel = svm.LinearSVR(C=1000)\n\n# Print some information about the linear model and its parameters:\nprint(model)\n\n# Train the model using CV and multiple scoring on the data we have prepared:\ncv_results = cross_validate(model, # Provide our model to the CV-function\n                            X, # Provide all the features (in real life only the training-data)\n                            y, # Provide all the \"correct answers\" (in real life only the training-data)\n                            scoring=('r2', 'neg_mean_squared_error', 'neg_mean_absolute_error'), \n                            cv=5 # Cross-validate using 5-fold (K-Fold method) cross-validation splits\n                           )\n\nMAE  = -cv_results['test_neg_mean_absolute_error']\nRMSE = np.sqrt(-cv_results['test_neg_mean_squared_error'])\nR2   = cv_results['test_r2']\n\nprint('\\n-------------- Scores ---------------')\nprint('Average R^2:\\t {:.2f} (+/- {:.2f})'.format(R2.mean(), R2.std()))\nprint('Average MAE:\\t {:.2f} (+/- {:.2f})'.format(MAE.mean(), MAE.std()))\nprint('Average RMSE:\\t {:.2f} (+/- {:.2f})'.format(RMSE.mean(), RMSE.std()))"],"metadata":{},"outputs":[],"execution_count":25},{"cell_type":"markdown","source":["Not good, not good at all.. What happened?\n\nIt turns out that the default inner workings of this type of model works better with normalized/scaled input. There are several ways to scale the input data, but the easiest and most basic way to do this is to use sklearn's StandardScaler, which we have done a couple of times already.\n\nA \"scaler\" in sklearn is build to behave the same way as any other model:\n\nWe create it\nWe use the .fit() function to have it look at the input data we want to scale. The scaler then decides how it will have to scale the different features in order to have them all scaled the way we asked for.\nWe then call the .transform() function on the scaler in order for it to actually scale the data.\nHowever, if we transform/normalize the data before we train the model, we also have to inverse transform the results to get them in the units we are used to, and we also have to separately transform the test data before we use it to score our model.\n\nsklearn has a great system for doing these things, and more, automatically. It's called a pipeline. Have a look at the code below, and see if you can understand how it is set up. Then run the code and see if the performance of our model is more in the range we expected from a decent model:"],"metadata":{}},{"cell_type":"code","source":["# Shuffle the rows of the dataframe, since the train_test_split function will not do it for us:\ndf = df.sample(frac=1)\n# Select the columns/features from the Pandas dataframe that we want to use in the model:\nX = np.array(df[['Age', 'KM', 'Weight']])\n# X = np.array(df[['Age']])\ny = np.array(df['Price'])\n\n# Create a linear regression model that we can train:\nmodel = svm.LinearSVR(C=1000)\n\n# Print some information about the linear model and its parameters:\nprint(model)\n\nfrom sklearn.pipeline import make_pipeline\nreg_pipeline = make_pipeline(StandardScaler(), model)\n\n# Train the model using CV and multiple scoring on the data we have prepared:\ncv_results = cross_validate(reg_pipeline, # Provide our model to the CV-function\n                            X, # Provide all the features (in real life only the training-data)\n                            y, # Provide all the \"correct answers\" (in real life only the training-data)\n                            scoring=('r2', 'neg_mean_squared_error', 'neg_mean_absolute_error'), \n                            cv=5 # Cross-validate using 5-fold (K-Fold method) cross-validation splits\n                           )\n\nMAE  = -cv_results['test_neg_mean_absolute_error']\nRMSE = np.sqrt(-cv_results['test_neg_mean_squared_error'])\nR2   = cv_results['test_r2']\n\nprint('\\n-------------- Scores ---------------')\nprint('Average R^2:\\t {:.2f} (+/- {:.2f})'.format(R2.mean(), R2.std()))\nprint('Average MAE:\\t {:.2f} (+/- {:.2f})'.format(MAE.mean(), MAE.std()))\nprint('Average RMSE:\\t {:.2f} (+/- {:.2f})'.format(RMSE.mean(), RMSE.std()))"],"metadata":{},"outputs":[],"execution_count":27},{"cell_type":"markdown","source":["In short, we:\n1. Use the `make_pipeline` function to create a \"pipeline\" which contains a scaler and a model, in that order\n- We use the pipeline *just like we would use a pure model*\n\nPipelines are powerful and great tools, usable for many purposes. When we give the pipeline to the `cross_validate` function, it automatically takes care of the separate scaling of each of the 5 \"experiments\" it runs internally, and also makes sure that the scores it returns are in normal units."],"metadata":{}},{"cell_type":"markdown","source":["### Comparing models"],"metadata":{}},{"cell_type":"markdown","source":["See if you can run and understand parts of the code below, if you have time. See how easy it is to try different models in `sklearn`?"],"metadata":{}},{"cell_type":"code","source":["import time\nfrom sklearn import svm\nfrom sklearn import tree\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.model_selection import cross_validate, cross_val_predict\nfrom sklearn.kernel_ridge import KernelRidge\nfrom sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n# Shuffle the rows of the dataframe, since the train_test_split function will not do it for us:\ndf = df.sample(frac=1)\n# Select the columns/features from the Pandas dataframe that we want to use in the model:\nX = np.array(df[['Age', 'KM', 'Weight']])\n# X = np.array(df[['Age']])\ny = np.array(df['Price'])\n\n# Choose and initialize the model:\nmodel = []\nmodel.append(('NuSVR_rbf', svm.NuSVR(kernel='rbf', C=5, nu=0.5)))\nmodel.append(('SVR_rbf\\t', svm.SVR(kernel='rbf', C=10000, epsilon=0.1, gamma='auto')))\nmodel.append(('SVR_poly', svm.SVR(kernel='poly', degree=3, gamma='auto', C=100, epsilon=0.1)))\nmodel.append(('SVR_linear', svm.LinearSVR(C=1000)))\nmodel.append(('KRR\\t', KernelRidge(kernel='rbf', alpha=0.001, gamma=1)))\nmodel.append(('tree\\t', tree.DecisionTreeRegressor(criterion='mse')))\nmodel.append(('GBR\\t' , GradientBoostingRegressor(n_estimators=70, max_depth=5, verbose=False)))\nmodel.append(('RF\\t', RandomForestRegressor(n_estimators=20)))\nmodel.append(('linreg\\t', LinearRegression()))\n\n\nprint('\\n-------------- Scores ---------------')\nprint('Model:\\t\\ttime:\\tR^2:\\tsqrt(MSE)\\tMAE')\nfor i in range(len(model)):\n    print('%s\\t' % model[i][0], end='')\n    # Initialize regression pipeline with scaling and model\n    reg_pipeline = make_pipeline(StandardScaler(), model[i][1])\n    \n    t0 = time.time()\n    # Train the model using CV and multiple scoring on the data we have prepared:\n    cv_results = cross_validate(reg_pipeline, # Provide our model to the CV-function\n                                X, # Provide all the features (in real life only the training-data)\n                                y, # Provide all the \"correct answers\" (in real life only the training-data)\n                                scoring=('r2', 'neg_mean_squared_error', 'neg_mean_absolute_error'), \n                                cv=5 # Cross-validate using 5-fold (K-Fold method) cross-validation splits\n                               )\n    print('%.3fs\\t' % (time.time() - t0), end='')\n\n    MAE  = -cv_results['test_neg_mean_absolute_error']\n    RMSE = np.sqrt(-cv_results['test_neg_mean_squared_error'])\n    R2   = cv_results['test_r2']\n    \n    # Print score:\n    print('{0:.4f}'.format(R2.mean()), end='')\n    print('\\t{0:.2f}'.format(RMSE.mean()), end='')\n    print('\\t\\t{0:.2f}'.format(MAE.mean()))\nprint('\\nPerformance is given wrt. the cross-validation hold-out dataset (the validation dataset).')"],"metadata":{},"outputs":[],"execution_count":31},{"cell_type":"markdown","source":["If you want to return to this lab after the workshop is over, feel free to:\n- Try to adjust the various models in the code cell above, and see if you can find the \"optimal model\" by hand-tuning some parameters to the models.\n- If you are adept at `sklearn` already: Implement a `GridSearch` for one or several models above to automatically scan for the best model parameters.\n- Use a more advanced model than the `SGDRegressor` in the \"Learning Curves\" you made earlier, or change the parameters of the current model. How do the learning curves, per iteration, change?"],"metadata":{}},{"cell_type":"markdown","source":["###Evaluation and Validation - Overfitting"],"metadata":{}},{"cell_type":"markdown","source":["Let's have a look at the Decision tree that we used earlier. Please run the code below, where the decision tree is used with default parameters, look at the results, and then continue below."],"metadata":{}},{"cell_type":"code","source":["# Shuffle the rows of the dataframe, since the train_test_split function will not do it for us:\ndf = df.sample(frac=1)\n# Select the columns/features from the Pandas dataframe that we want to use in the model:\nX = np.array(df[['Age', 'KM', 'Weight']])\n# X = np.array(df[['Age']])\ny = np.array(df['Price'])\n\n# Create a linear regression model that we can train:\nmodel = tree.DecisionTreeRegressor(criterion='mse')\n# Print some information about the linear model and its parameters:\nprint(model)\n\n# Train the model using CV and multiple scoring on the data we have prepared:\ncv_results = cross_validate(model, # Provide our model to the CV-function\n                            X, # Provide all the features (in real life only the training-data)\n                            y, # Provide all the \"correct answers\" (in real life only the training-data)\n                            scoring=('r2', 'neg_mean_squared_error', 'neg_mean_absolute_error'), \n                            cv=5 # Cross-validate using 5-fold (K-Fold method) cross-validation splits\n                           )\n\nMAE  = -cv_results['test_neg_mean_absolute_error']\nRMSE = np.sqrt(-cv_results['test_neg_mean_squared_error'])\nR2   = cv_results['test_r2']\n\nprint('\\n-------------- Scores on test-dataset ---------------')\nprint('Average R^2:\\t {:.2f} (+/- {:.2f})'.format(R2.mean(), R2.std()))\nprint('Average MAE:\\t {:.2f} (+/- {:.2f})'.format(MAE.mean(), MAE.std()))\nprint('Average RMSE:\\t {:.2f} (+/- {:.2f})'.format(RMSE.mean(), RMSE.std()))"],"metadata":{},"outputs":[],"execution_count":35},{"cell_type":"markdown","source":["Looks alright? Again, the decision tree is fast and simple to use, and it works with no scaling of the input. Let us however make a **very important point**: Until now, with the exception of the \"learning curves\" we looked at for the `SGDRegressor`, we have only looked at the **test-scores**, based on the test-dataset. Let's change this in the cell below, by calling the `train_`-version of the scores from the cross-validator:"],"metadata":{}},{"cell_type":"code","source":["MAE  = -cv_results['train_neg_mean_absolute_error']\nRMSE = np.sqrt(-cv_results['train_neg_mean_squared_error'])\nR2   = cv_results['train_r2']\n\nprint('\\n-------------- Scores on TRAIN-dataset ---------------')\nprint('Average R^2:\\t {:.2f} (+/- {:.2f})'.format(R2.mean(), R2.std()))\nprint('Average MAE:\\t {:.2f} (+/- {:.2f})'.format(MAE.mean(), MAE.std()))\nprint('Average RMSE:\\t {:.2f} (+/- {:.2f})'.format(RMSE.mean(), RMSE.std()))"],"metadata":{},"outputs":[],"execution_count":37},{"cell_type":"markdown","source":["What do you observe above? **This is some serious overfitting.** The decision tree has been given no limit on its depth, so it makes branches until **it has a leaf (end-node on the tree) for almost every datapoint in the train-dataset that we are using to train it**.\n\nWe therefore get extremely good scores on the train-dataset when we use the model. This shows that the model is unable to improve any more based on the data it has been given: **the model is too complex considering the amount of data we have available**.\n\nExercise: Try limiting the depth of the tree, and re-check the test- and train-scores. Did it help? Do you think the depth-limited model is a better model overall?"],"metadata":{}},{"cell_type":"markdown","source":["###Evaluation and Validation - Learning curves"],"metadata":{}},{"cell_type":"markdown","source":["Earlier we looked at learning curves where we assessed some scores as the model went through training iterations. Another very interesting thing to look at is how our model scores as we **introduce it to more and more data**. Run the cell below to get some code into the system that will help us plot this:"],"metadata":{}},{"cell_type":"code","source":["from sklearn.model_selection import learning_curve\nfrom sklearn.model_selection import ShuffleSplit\n\n\ndef plot_learning_curve(ax, estimator, title, X, y, ylim=None, cv=None,\n                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 20)):\n    \"\"\"\n    Generate a simple plot of the test and training learning curve.\n\n    Parameters\n    ----------\n    estimator : object type that implements the \"fit\" and \"predict\" methods\n        An object of that type which is cloned for each validation.\n\n    title : string\n        Title for the chart.\n\n    X : array-like, shape (n_samples, n_features)\n        Training vector, where n_samples is the number of samples and\n        n_features is the number of features.\n\n    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n        Target relative to X for classification or regression;\n        None for unsupervised learning.\n\n    ylim : tuple, shape (ymin, ymax), optional\n        Defines minimum and maximum yvalues plotted.\n\n    cv : int, cross-validation generator or an iterable, optional\n        Determines the cross-validation splitting strategy.\n        Possible inputs for cv are:\n          - None, to use the default 3-fold cross-validation,\n          - integer, to specify the number of folds.\n          - An object to be used as a cross-validation generator.\n          - An iterable yielding train/test splits.\n\n        For integer/None inputs, if ``y`` is binary or multiclass,\n        :class:`StratifiedKFold` used. If the estimator is not a classifier\n        or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.\n\n        Refer :ref:`User Guide <cross_validation>` for the various\n        cross-validators that can be used here.\n\n    n_jobs : integer, optional\n        Number of jobs to run in parallel (default 1).\n    \"\"\"\n\n    ax.set_title(title)\n    if ylim is not None:\n        ax.set_ylim(*ylim)\n    ax.set_xlabel(\"Training examples\")\n    ax.set_ylabel(\"Score\")\n    train_sizes, train_scores, test_scores = learning_curve(\n        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n    ax.grid()\n\n    ax.fill_between(train_sizes, train_scores_mean - train_scores_std,\n                     train_scores_mean + train_scores_std, alpha=0.1,\n                     color=\"r\")\n    ax.fill_between(train_sizes, test_scores_mean - test_scores_std,\n                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n    ax.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n             label=\"Training score\")\n    ax.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n             label=\"Cross-validation score\")\n\n    ax.legend(loc=\"best\")\n    return"],"metadata":{},"outputs":[],"execution_count":41},{"cell_type":"markdown","source":["We now add two engineered features to our dataset, so that we have more to play with:"],"metadata":{}},{"cell_type":"code","source":["df['Age2'] = df['Age'].values**2\ndf['KMlog'] = np.log(df['KM'].values)"],"metadata":{},"outputs":[],"execution_count":43},{"cell_type":"markdown","source":["We now load a variety of features into different X's, and to get you started we've done the code already. We also do test-train splits, even if we later will do cross-validation: this time we do cross-validation properly, more or less."],"metadata":{}},{"cell_type":"code","source":["# Select the columns/features from the Pandas dataframe that we want to use in the model:\nx2D = df[['Age', 'KM']].as_matrix()\nx5D = np.array(df[['Age', 'KM', 'HP', 'CC', 'Weight']])\nx7D = df[['Age', 'KM', 'HP', 'CC', 'Weight', 'Age2', 'KMlog']].as_matrix()\n\ny = np.array(df['Price'])\n\n# Do a test-train-split like we did previously:\nX0_train, X0_test, y0_train, y0_test = train_test_split(x2D, y, train_size=0.8)\nX1_train, X1_test, y1_train, y1_test = train_test_split(x5D, y, train_size=0.8)\nX2_train, X2_test, y2_train, y2_test = train_test_split(x7D, y, train_size=0.8)"],"metadata":{},"outputs":[],"execution_count":45},{"cell_type":"markdown","source":["We then choose a model. The LinearRegression is not really a model that trains at all, so please replace it with something more 'trainable' after you've had a look at the curves the first time."],"metadata":{}},{"cell_type":"code","source":["# Create a linear regression model that we can train:\nlinreg = LinearRegression()"],"metadata":{},"outputs":[],"execution_count":47},{"cell_type":"markdown","source":["Here we go! Run the code below, and see if you can play with the plotting range (max/min) and the model. Can you get some insight into model complexity and data quantity?"],"metadata":{}},{"cell_type":"code","source":["# Cross validation with 100 iterations to get smoother mean test and train\n# score curves, each time with 20% data randomly selected as a validation set.\ncv = ShuffleSplit(n_splits=100, test_size=0.2, random_state=0)\nfig, ax = plt.subplots(3, figsize=(20, 25))\n\nplot_learning_curve(ax[0], linreg, \"Learning Curves 2D (Linear Regression)\", X0_train, y0_train, ylim=(0.77, 0.97), cv=cv, n_jobs=4)\n\nplot_learning_curve(ax[1], linreg, \"Learning Curves 5D (Linear Regression)\", X1_train, y1_train, ylim=(0.8, 0.9), cv=cv, n_jobs=4)\n\nplot_learning_curve(ax[2], linreg, \"Learning Curves 7D (Linear Regression)\", X2_train, y2_train, ylim=(0.8, 0.9), cv=cv, n_jobs=4)\n\ndisplay(fig)"],"metadata":{},"outputs":[],"execution_count":49},{"cell_type":"markdown","source":["###Higher order polynomial regression"],"metadata":{}},{"cell_type":"code","source":["# Make a copy of our \"original\" data, so that we avoid later confusion\ndf_poly = df.copy(deep=True)\n# When we do a mathematical operation on a Pandas Series object, like the \"Age\"-column, Pandas will automatically do the operation on each element in that Series (since it is build on NumPy, and normally acts as NumPy would)\ndf_poly['Age**2'] = df['Age']**2\n\n# Shuffle the rows of the dataframe, since the train_test_split function will not do it for us:\ndf_poly = df_poly.sample(frac=1)\n# Select the columns/features from the Pandas dataframe that we want to use in the model:\nX_poly = np.array(df_poly[['Age', 'Age**2']])\n# X_poly = np.array(df_poly[['Age']])\ny_poly = np.array(df_poly['Price'])\n\n# Create a linear regression model that we can train:\nlinreg_poly = LinearRegression()\n# Print some information about the linear model and its parameters:\nprint(linreg_poly)\n\n# Train the model using CV and multiple scoring on the data we have prepared:\ncv_results = cross_validate(linreg_poly, # Provide our model to the CV-function\n                            X_poly, # Provide all the features (in real life only the training-data)\n                            y_poly, # Provide all the \"correct answers\" (in real life only the training-data)\n                            scoring=('r2', 'neg_mean_squared_error', 'neg_mean_absolute_error'), \n                            cv=5 # Cross-validate using 5-fold (K-Fold method) cross-validation splits\n                           )\n\nMAE  = -cv_results['test_neg_mean_absolute_error']\nRMSE = np.sqrt(-cv_results['test_neg_mean_squared_error'])\nR2   = cv_results['test_r2']\n\n\nprint('Average R^2:\\t {:.2f} (+/- {:.2f})'.format(R2.mean(), R2.std()))\nprint('Average MAE:\\t {:.2f} (+/- {:.2f})'.format(MAE.mean(), MAE.std()))\nprint('Average RMSE:\\t {:.2f} (+/- {:.2f})'.format(RMSE.mean(), RMSE.std()))\n\ny_pred = cross_val_predict(linreg_poly, \n                            X_poly,\n                            y_poly,\n                            cv=5\n                           )\n\nfig, ax = plt.subplots(1, 1, figsize= (20, 15))\nax.scatter(df_poly['Age'], y_poly)\nax.plot(df_poly['Age'], y_pred, 'ro')\nax.set_title('Price of used cars as a function of age')\nax.set_ylabel('Price [$]')\nax.set_xlabel('Age [Months]')\ndisplay(fig)"],"metadata":{},"outputs":[],"execution_count":51},{"cell_type":"markdown","source":["This concludes the model training, selection, and evaluation lab.\n\nIn this lab you investigated techniques for training, selecting, and evaluating machine learning models,m with a focus on two \"classical\" categories of models: regression and classification."],"metadata":{}}],"metadata":{"name":"04 Advanced Regression with Azure Databricks","notebookId":2793193203916631},"nbformat":4,"nbformat_minor":0}